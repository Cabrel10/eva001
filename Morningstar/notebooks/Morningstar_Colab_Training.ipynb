{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morningstar: Entraînement sur Google Colab\n",
    "\n",
    "Ce notebook permet d'entraîner le modèle Morningstar en utilisant les ressources GPU de Google Colab.\n",
    "\n",
    "**Étapes:**\n",
    "1.  Exécuter les cellules d'installation et de configuration.\n",
    "2.  Exécuter la cellule \"Upload Fichier de Données\" et téléverser votre fichier de données (ex: `full_dataset.parquet`).\n",
    "3.  Exécuter les cellules restantes pour préparer les données, entraîner le modèle et sauvegarder/télécharger le résultat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation des Dépendances et Clonage du Projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des bibliothèques nécessaires\n",
    "!pip install -q tensorflow pyarrow wandb pandas numpy\n",
    "\n",
    "# Vérification GPU\n",
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print(f\"GPU disponible: {gpu_devices}\")\n",
    "    # Configuration pour éviter les erreurs OOM sur certaines cartes\n",
    "    try:\n",
    "        for gpu in gpu_devices:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth activé pour les GPUs.\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Erreur lors de l'activation de memory growth: {e}\")\n",
    "else:\n",
    "    print(\"Aucun GPU détecté. L'entraînement se fera sur CPU (peut être très lent).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clonage du dépôt GitHub (contient le code source du modèle et des utilitaires)\n",
    "!git clone https://github.com/Cabrel10/eva001.git\n",
    "%cd eva001\n",
    "\n",
    "# Installation des dépendances spécifiques du projet\n",
    "!pip install -q ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Weights & Biases (W&B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connexion à W&B (utilise la clé API fournie)\n",
    "!wandb login a1478933771f0389426436c0de1c39585a5a452c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Upload Fichier de Données\n",
    "\n",
    "Exécutez la cellule suivante et utilisez le bouton \"Choisir les fichiers\" pour téléverser votre fichier de données Parquet (par exemple, `full_dataset.parquet`). Assurez-vous que le nom du fichier correspond à celui utilisé dans la cellule de préparation des données plus bas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"Veuillez téléverser votre fichier de données Parquet...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Vérification - affiche les noms des fichiers téléversés\n",
    "for fn in uploaded.keys():\n",
    "  print(f'Fichier \"{fn}\" téléversé avec succès ({len(uploaded[fn])} bytes)')\n",
    "\n",
    "# Définir le nom du fichier pour la suite (MODIFIEZ SI NECESSAIRE)\n",
    "uploaded_filename = list(uploaded.keys())[0] # Prend le premier fichier téléversé\n",
    "print(f\"Nom du fichier retenu pour la préparation: {uploaded_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Préparation des Données\n",
    "\n",
    "Cette section charge le fichier Parquet téléversé, sélectionne les features, gère les valeurs manquantes, normalise les données, crée les séquences et génère les labels (Buy/Sell/Hold) en utilisant la logique du projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Configuration du logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Importer les classes nécessaires depuis le projet cloné\n",
    "try:\n",
    "    from Morningstar.configs.morningstar_config import MorningstarConfig\n",
    "    from Morningstar.workflows.morningstar_training import MorningstarTrainingWorkflow\n",
    "except ImportError as e:\n",
    "    logger.error(f\"Erreur d'importation des modules du projet: {e}\")\n",
    "    logger.error(\"Assurez-vous que le clonage et l'installation (pip install .) ont réussi.\")\n",
    "    raise\n",
    "\n",
    "# Chemin vers le fichier uploadé dans Colab\n",
    "# Assurez-vous que 'uploaded_filename' a été défini correctement dans la cellule précédente\n",
    "colab_data_path = f\"/content/{uploaded_filename}\"\n",
    "\n",
    "if not os.path.exists(colab_data_path):\n",
    "    logger.error(f\"Le fichier de données '{colab_data_path}' n'a pas été trouvé !\")\n",
    "    logger.error(\"Vérifiez que le fichier a été correctement téléversé et que le nom est correct.\")\n",
    "    raise FileNotFoundError(colab_data_path)\n",
    "\n",
    "logger.info(f\"Utilisation du fichier de données: {colab_data_path}\")\n",
    "\n",
    "# Instancier la configuration\n",
    "config = MorningstarConfig()\n",
    "\n",
    "# *** Point crucial : Modifier la configuration pour utiliser le fichier uploadé ***\n",
    "# Crée une copie ou modifie l'instance pour pointer vers le bon chemin\n",
    "class ColabConfig(MorningstarConfig):\n",
    "    DATA_PATH: str = colab_data_path\n",
    "\n",
    "colab_config = ColabConfig()\n",
    "\n",
    "# Instancier le workflow avec la configuration adaptée\n",
    "workflow = MorningstarTrainingWorkflow(colab_config)\n",
    "\n",
    "# Préparer les données (chargement, features, NaN, scaling, séquences, labels, split)\n",
    "logger.info(\"Début de la préparation des données...\")\n",
    "try:\n",
    "    (train_seq, train_labels), (val_seq, val_labels) = workflow.prepare_data()\n",
    "    logger.info(\"Préparation des données terminée.\")\n",
    "    logger.info(f\"Shape Train Sequences: {train_seq.shape}, Train Labels: {train_labels.shape}\")\n",
    "    logger.info(f\"Shape Validation Sequences: {val_seq.shape}, Validation Labels: {val_labels.shape}\")\n",
    "\n",
    "    # Créer les tuples pour l'entraînement\n",
    "    train_data = (train_seq, train_labels)\n",
    "    val_data = (val_seq, val_labels)\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erreur lors de la préparation des données: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialisation de l'Expérience W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# Initialisation de l'expérience W&B pour le suivi\n",
    "try:\n",
    "    wandb.init(project=\"morningstar-colab-training\", entity=\"cabrelkaka-morningstar\", config=colab_config.__dict__)\n",
    "    logger.info(\"Wandb initialisé avec succès.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erreur lors de l'initialisation de Wandb: {e}\")\n",
    "    # Continuer sans W&B si l'initialisation échoue ? Ou arrêter ?\n",
    "    # Pour l'instant, on continue mais on log l'erreur.\n",
    "    wandb_active = False\n",
    "else:\n",
    "    wandb_active = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Chargement et Compilation du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Morningstar.model.architecture.morningstar_model import MorningstarTradingModel\n",
    "\n",
    "# Déterminer input_shape et num_classes à partir des données préparées\n",
    "input_shape = train_data[0].shape[1:] # (time_window, num_features)\n",
    "num_classes = train_data[1].shape[1] # Nombre de classes (Buy, Sell, Hold -> 3)\n",
    "\n",
    "logger.info(f\"Initialisation du modèle avec input_shape={input_shape}, num_classes={num_classes}\")\n",
    "\n",
    "# Instancier le modèle\n",
    "model_instance = MorningstarTradingModel(\n",
    "    input_shape=input_shape,\n",
    "    num_classes=num_classes,\n",
    "    # Passer d'autres paramètres d'architecture si nécessaire depuis colab_config\n",
    "    cnn_filters=colab_config.cnn_filters,\n",
    "    lstm_units=colab_config.lstm_units,\n",
    "    dense_units=colab_config.dense_units\n",
    ")\n",
    "\n",
    "# Compiler le modèle\n",
    "model_instance.compile_model(learning_rate=colab_config.learning_rate)\n",
    "logger.info(\"Modèle compilé.\")\n",
    "model_instance.model.summary() # Afficher le résumé du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Configuration des Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Définition des callbacks pour l'entraînement\n",
    "callbacks = [\n",
    "    # Sauvegarde le meilleur modèle basé sur la perte de validation\n",
    "    ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', verbose=1),\n",
    "    # Arrête l'entraînement si la perte de validation ne s'améliore pas pendant 15 époques\n",
    "    EarlyStopping(patience=15, monitor='val_loss', restore_best_weights=True, verbose=1)\n",
    "]\n",
    "\n",
    "# Ajouter le callback W&B si l'initialisation a réussi\n",
    "if wandb_active:\n",
    "    try:\n",
    "        from wandb.keras import WandbCallback\n",
    "        callbacks.append(WandbCallback())\n",
    "        logger.info(\"Callback Wandb ajouté.\")\n",
    "    except ImportError:\n",
    "        logger.warning(\"Impossible d'importer WandbCallback. Le suivi W&B sera limité.\")\n",
    "\n",
    "logger.info(f\"Callbacks configurés: {callbacks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Entraînement du Modèle\n",
    "\n",
    "L'entraînement peut prendre du temps en fonction de la taille des données et du nombre d'époques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Début de l'entraînement...\")\n",
    "\n",
    "# Utilisation de MirroredStrategy si plusieurs GPUs sont détectés (facultatif)\n",
    "strategy = tf.distribute.MirroredStrategy() if len(gpu_devices) > 1 else tf.distribute.get_strategy()\n",
    "logger.info(f\"Utilisation de la stratégie de distribution: {strategy.__class__.__name__}\")\n",
    "\n",
    "with strategy.scope():\n",
    "    # Ré-instancier et compiler le modèle dans le scope de la stratégie si nécessaire\n",
    "    # (Keras gère souvent cela automatiquement, mais c'est plus sûr pour certains cas)\n",
    "    # model_instance_scoped = MorningstarTradingModel(...) \n",
    "    # model_instance_scoped.compile_model(...)\n",
    "    \n",
    "    history = model_instance.model.fit(\n",
    "        x=train_data[0], # Séquences d'entraînement\n",
    "        y=train_data[1], # Labels d'entraînement\n",
    "        epochs=colab_config.epochs,\n",
    "        batch_size=colab_config.batch_size,\n",
    "        validation_data=val_data, # Données de validation (séquences, labels)\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "logger.info(\"Entraînement terminé.\")\n",
    "\n",
    "# Optionnel: Afficher les métriques finales\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "logger.info(f\"Perte finale (entraînement): {final_train_loss:.4f}\")\n",
    "logger.info(f\"Perte finale (validation): {final_val_loss:.4f}\")\n",
    "\n",
    "# Terminer l'exécution W&B si active\n",
    "if wandb_active:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Sauvegarde sur Google Drive (Optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "try:\n",
    "    drive.mount('/content/drive')\n",
    "    drive_path = '/content/drive/MyDrive/Morningstar_Models/' # Chemin sur votre Drive\n",
    "    os.makedirs(drive_path, exist_ok=True) # Crée le dossier s'il n'existe pas\n",
    "    \n",
    "    model_save_path = os.path.join(drive_path, 'best_model_colab.h5')\n",
    "    \n",
    "    if os.path.exists('best_model.h5'):\n",
    "        !cp best_model.h5 \"{model_save_path}\"\n",
    "        logger.info(f\"Modèle sauvegardé sur Google Drive: {model_save_path}\")\n",
    "    else:\n",
    "        logger.warning(\"Le fichier 'best_model.h5' n'a pas été trouvé. Sauvegarde sur Drive annulée.\")\n",
    "        logger.warning(\"(Cela peut arriver si EarlyStopping n'a pas trouvé de meilleur modèle que l'initial)\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erreur lors de la sauvegarde sur Google Drive: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Téléchargement du Modèle Entraîné\n",
    "\n",
    "Exécutez la cellule suivante pour télécharger le fichier `best_model.h5` (contenant les poids du meilleur modèle trouvé pendant l'entraînement) sur votre machine locale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "if os.path.exists('best_model.h5'):\n",
    "    print(\"Téléchargement de best_model.h5...\")\n",
    "    files.download('best_model.h5')\n",
    "else:\n",
    "    logger.error(\"Le fichier 'best_model.h5' n'a pas été trouvé pour le téléchargement.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
