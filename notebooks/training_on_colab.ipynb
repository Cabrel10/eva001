{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update && apt-get install -y tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement du Modèle Morningstar sur Google Colab\n",
    "\n",
    "Ce notebook guide à travers les étapes nécessaires pour entraîner le modèle hybride multi-tâches Morningstar dans l'environnement Google Colab.\n",
    "\n",
    "**Étapes principales :**\n",
    "1. Configuration de l'environnement (clonage du repo, installation des dépendances, exécution du pipeline de données).\n",
    "2. Chargement et préparation des données pour un actif spécifique.\n",
    "3. Définition et compilation de l'architecture du modèle Morningstar.\n",
    "4. Entraînement du modèle avec suivi des performances.\n",
    "5. Évaluation du modèle entraîné.\n",
    "6. Visualisation des courbes d'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration de l'Environnement\n",
    "\n",
    "Nous devons d'abord cloner le dépôt contenant le code du projet, installer les dépendances et générer les datasets via le pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Clonage du Dépôt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le répertoire de base pour le clonage\n",
    "REPO_DIR = \"/content/CryptoRobot\"\n",
    "\n",
    "# Supprimer le répertoire s'il existe déjà pour un clonage propre\n",
    "!rm -rf {REPO_DIR}\n",
    "\n",
    "# Cloner la branche spécifique 'mise-a-jour' du dépôt\n",
    "# Assurez-vous que le dépôt est accessible (public ou via token/clé SSH si privé)\n",
    "!git clone -b mise-a-jour https://github.com/Cabrel10/eva001.git {REPO_DIR}\n",
    "\n",
    "# Vérifier que le clonage a réussi\n",
    "!ls -l /content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Installation des Dépendances et Exécution du Pipeline\n",
    "\n",
    "Nous allons maintenant nous déplacer dans le répertoire cloné et exécuter les commandes nécessaires depuis cet emplacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se déplacer dans le répertoire cloné\n",
    "%cd {REPO_DIR}\n",
    "\n",
    "# Vérifier le répertoire courant actuel\n",
    "!pwd\n",
    "\n",
    "# Installer les dépendances depuis ce répertoire\n",
    "print(\"\\n--- Installation des dépendances ---\")\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Exécuter le pipeline de données complet depuis ce répertoire\n",
    "print(\"\\n--- Lancement du pipeline complet de données ---\")\n",
    "!python tests/manual_tests/test_full_pipeline_all_assets.py\n",
    "\n",
    "print(\"\\n--- Pipeline de données terminé. Vérification des fichiers générés: ---\")\n",
    "!ls -l data/processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement et Préparation des Données\n",
    "\n",
    "Maintenant que les données sont générées dans `data/processed/` (relativement au répertoire du projet), nous pouvons les charger.\n",
    "Nous devons ajouter le répertoire du projet au `sys.path` pour que Python trouve les modules locaux (`model.training.data_loader`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# S'assurer que le répertoire courant est bien celui du projet\n",
    "PROJECT_ROOT = \"/content/CryptoRobot\" # Doit correspondre au REPO_DIR ci-dessus\n",
    "if Path.cwd() != Path(PROJECT_ROOT):\n",
    "    print(f\"Changement du répertoire courant vers {PROJECT_ROOT}\")\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "!pwd # Confirmer\n",
    "\n",
    "# Ajouter le répertoire racine du projet au PYTHONPATH\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    print(f\"Ajout de {PROJECT_ROOT} au sys.path\")\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "# Importer le data_loader maintenant que le path est correct\n",
    "try:\n",
    "    from model.training.data_loader import load_and_split_data\n",
    "except ModuleNotFoundError:\n",
    "    print(f\"ERREUR: Impossible d'importer 'model.training.data_loader'. Vérifiez la structure du projet dans {PROJECT_ROOT} et le sys.path.\")\n",
    "    # Afficher le contenu pour débogage\n",
    "    print(\"Contenu de {PROJECT_ROOT}:\")\n",
    "    !ls -l {PROJECT_ROOT}\n",
    "    print(\"Contenu de {PROJECT_ROOT}/model/training:\")\n",
    "    !ls -l {PROJECT_ROOT}/model/training\n",
    "    raise # Arrêter l'exécution\n",
    "\n",
    "# --- Configuration --- \n",
    "ASSET_NAME = 'btc' # Choisir l'actif (btc, eth, sol, etc.)\n",
    "DATA_DIR = Path('data/processed') # Chemin relatif à PROJECT_ROOT\n",
    "FILE_PATH = DATA_DIR / f\"{ASSET_NAME}_final.parquet\"\n",
    "# --- IMPORTANT --- \n",
    "# Vérifiez que les colonnes générées par votre pipeline correspondent à celles-ci.\n",
    "# Si l'erreur persiste, ajustez cette liste ou corrigez le pipeline.\n",
    "LABEL_COLUMNS = ['trading_signal', 'volatility', 'market_regime']\n",
    "VALIDATION_SPLIT = 0.2 # % des données pour la validation (fin de série)\n",
    "\n",
    "print(f\"Chargement des données pour : {ASSET_NAME} depuis {FILE_PATH}\")\n",
    "\n",
    "# Charger les données en tant que Tensors\n",
    "X = None\n",
    "y_dict = None\n",
    "if FILE_PATH.exists():\n",
    "    try:\n",
    "        X, y_dict = load_and_split_data(FILE_PATH, label_columns=LABEL_COLUMNS, as_tensor=True)\n",
    "        print(f\"Données chargées : X shape={X.shape}, Labels={list(y_dict.keys())}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"ERREUR lors du chargement/split : {e}\")\n",
    "        print(\"Vérifiez que les LABEL_COLUMNS ci-dessus correspondent aux colonnes dans le fichier Parquet.\")\n",
    "        # Pour inspecter les colonnes : df = pd.read_parquet(FILE_PATH); print(df.columns)\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur inattendue est survenue lors du chargement : {e}\")\n",
    "else:\n",
    "     print(f\"ERREUR : Le fichier {FILE_PATH} n'a pas été trouvé. Vérifiez que le pipeline l'a bien généré pour cet actif.\")\n",
    "\n",
    "# Continuer seulement si les données ont été chargées correctement\n",
    "if X is not None and y_dict is not None:\n",
    "    # Séparation Train/Validation (temporelle)\n",
    "    num_samples = X.shape[0]\n",
    "    num_val_samples = int(num_samples * VALIDATION_SPLIT)\n",
    "    num_train_samples = num_samples - num_val_samples\n",
    "\n",
    "    X_train, X_val = X[:num_train_samples], X[num_train_samples:]\n",
    "    y_train_dict = {name: tensor[:num_train_samples] for name, tensor in y_dict.items()}\n",
    "    y_val_dict = {name: tensor[num_train_samples:] for name, tensor in y_dict.items()}\n",
    "\n",
    "    print(f\"Séparation Train/Validation : Train={num_train_samples}, Val={num_val_samples}\")\n",
    "    print(f\"Shapes : X_train={X_train.shape}, X_val={X_val.shape}\")\n",
    "    print(f\"Labels Train : {[f'{k}:{v.shape}' for k, v in y_train_dict.items()]}\")\n",
    "    print(f\"Labels Val : {[f'{k}:{v.shape}' for k, v in y_val_dict.items()]}\")\n",
    "else:\n",
    "    print(\"\\nArrêt prématuré car les données n'ont pas pu être chargées correctement.\")\n",
    "    # Assigner des valeurs vides pour éviter les erreurs dans les cellules suivantes si on les exécute quand même\n",
    "    X_train, X_val, y_train_dict, y_val_dict = None, None, {}, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Définition et Compilation du Modèle Morningstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuer seulement si les données d'entraînement existent\n",
    "if X_train is not None:\n",
    "    # Importer ici pour s'assurer que sys.path est correct\n",
    "    try:\n",
    "        from model.architecture.enhanced_hybrid_model import build_enhanced_hybrid_model\n",
    "    except ModuleNotFoundError:\n",
    "        print(\"ERREUR: Impossible d'importer 'model.architecture.enhanced_hybrid_model'. Vérifiez la structure.\")\n",
    "        raise\n",
    "\n",
    "    # --- Configuration du Modèle --- \n",
    "    INPUT_SHAPE = (X_train.shape[1],) \n",
    "    # Doit correspondre à la cardinalité des labels de classification\n",
    "    NUM_TRADING_CLASSES = 5 # Ex: Strong Sell -> Strong Buy\n",
    "    NUM_REGIME_CLASSES = 3  # Ex: Bull, Bear, Sideways\n",
    "    LEARNING_RATE = 0.001\n",
    "\n",
    "    print(\"Construction du modèle Morningstar...\")\n",
    "    model = build_enhanced_hybrid_model(input_shape=INPUT_SHAPE, \n",
    "                                        num_trading_classes=NUM_TRADING_CLASSES, \n",
    "                                        num_regime_classes=NUM_REGIME_CLASSES)\n",
    "\n",
    "    model.summary() # Afficher l'architecture\n",
    "\n",
    "    # Définir les pertes et métriques (doivent correspondre aux noms des couches de sortie)\n",
    "    # Assurez-vous que ces noms correspondent à ceux définis dans build_enhanced_hybrid_model\n",
    "    losses = {\n",
    "        'trading_signal_output': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        'volatility_output': tf.keras.losses.MeanSquaredError(),\n",
    "        'market_regime_output': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "    }\n",
    "    metrics = {\n",
    "        'trading_signal_output': ['accuracy'],\n",
    "        'volatility_output': [tf.keras.metrics.RootMeanSquaredError(name='rmse'), 'mae'],\n",
    "        'market_regime_output': ['accuracy']\n",
    "    }\n",
    "    # loss_weights = {'trading_signal_output': 1.0, 'volatility_output': 0.5, 'market_regime_output': 0.8} # Optionnel\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "    print(\"Compilation du modèle...\")\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss=losses, \n",
    "                  metrics=metrics)\n",
    "                  # loss_weights=loss_weights)\n",
    "\n",
    "    print(\"Modèle compilé.\")\n",
    "else:\n",
    "    print(\"Définition/Compilation du modèle sautée car les données n'ont pas été chargées.\")\n",
    "    model = None # Pour éviter les erreurs suivantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entraînement du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuer seulement si le modèle est défini et les données existent\n",
    "if model is not None and X_train is not None:\n",
    "    # --- Configuration de l'Entraînement ---\n",
    "    EPOCHS = 50\n",
    "    BATCH_SIZE = 32\n",
    "    # Utiliser le même ASSET_NAME que pour le chargement\n",
    "    MODEL_SAVE_DIR = Path('model/training') # Chemin relatif au répertoire du projet\n",
    "    MODEL_SAVE_PATH = MODEL_SAVE_DIR / f'{ASSET_NAME}_morningstar_colab.h5'\n",
    "\n",
    "    # Créer le répertoire de sauvegarde si nécessaire\n",
    "    MODEL_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Callbacks\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=MODEL_SAVE_PATH,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_loss', # Surveiller la perte totale de validation\n",
    "        mode='min',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=10, # Nb epochs sans amélioration avant arrêt\n",
    "        verbose=1,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    print(f\"Début de l'entraînement pour {EPOCHS} epochs...\")\n",
    "    print(f\"Le meilleur modèle sera sauvegardé dans : {MODEL_SAVE_PATH}\")\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train_dict,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_val, y_val_dict),\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"Entraînement terminé.\")\n",
    "else:\n",
    "    print(\"Entraînement sauté car les données ou le modèle ne sont pas prêts.\")\n",
    "    history = None # Pour éviter les erreurs suivantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Évaluation du Modèle\n",
    "\n",
    "Évaluons les performances du modèle (avec les poids restaurés du meilleur epoch grâce à `restore_best_weights=True` dans EarlyStopping) sur l'ensemble de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuer seulement si le modèle a été entraîné et les données de validation existent\n",
    "if model is not None and X_val is not None:\n",
    "    print(\"Évaluation du meilleur modèle sur l'ensemble de validation...\")\n",
    "    results = model.evaluate(X_val, y_val_dict, batch_size=BATCH_SIZE, verbose=0)\n",
    "\n",
    "    print(\"Résultats de l'évaluation:\")\n",
    "    results_dict = {}\n",
    "    try:\n",
    "        for name, value in zip(model.metrics_names, results):\n",
    "            results_dict[name] = value\n",
    "            print(f\"  - {name}: {value:.4f}\")\n",
    "    except AttributeError:\n",
    "        print(\"Impossible de récupérer model.metrics_names, affichage brut:\", results)\n",
    "\n",
    "    # Optionnel : Charger explicitement le meilleur modèle sauvegardé si EarlyStopping n'a pas restauré les poids\n",
    "    # print(f\"\\nChargement du meilleur modèle depuis {MODEL_SAVE_PATH} pour vérification...\")\n",
    "    # best_model = tf.keras.models.load_model(MODEL_SAVE_PATH)\n",
    "    # results_best = best_model.evaluate(X_val, y_val_dict, batch_size=BATCH_SIZE, verbose=0)\n",
    "    # print(\"Résultats du modèle chargé:\")\n",
    "    # try:\n",
    "    #     for name, value in zip(best_model.metrics_names, results_best):\n",
    "    #         print(f\"  - {name}: {value:.4f}\")\n",
    "    # except AttributeError:\n",
    "    #     print(\"Impossible de récupérer model.metrics_names, affichage brut:\", results_best)\n",
    "else:\n",
    "    print(\"Évaluation sautée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualisation des Courbes d'Apprentissage\n",
    "\n",
    "Visualisons l'évolution des pertes et des métriques clés pendant l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuer seulement si l'entraînement a eu lieu\n",
    "if history is not None:\n",
    "    history_dict = history.history\n",
    "\n",
    "    # Clés disponibles dans l'historique\n",
    "    print(\"\\nClés disponibles dans l'historique:\", history_dict.keys())\n",
    "\n",
    "    # Créer les graphiques\n",
    "    # Vérifier si les clés existent avant de plotter pour éviter les erreurs\n",
    "    if 'loss' in history_dict and 'val_loss' in history_dict:\n",
    "        epochs_range = range(1, len(history_dict['loss']) + 1)\n",
    "        plt.figure(figsize=(15, 10))\n",
    "\n",
    "        # 1. Perte Totale\n",
    "        plt.subplot(2, 3, 1)\n",
    "        plt.plot(epochs_range, history_dict['loss'], label='Train Loss')\n",
    "        plt.plot(epochs_range, history_dict['val_loss'], label='Validation Loss')\n",
    "        plt.title('Total Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        # 2. Trading Signal Accuracy (si disponible)\n",
    "        if 'trading_signal_output_accuracy' in history_dict and 'val_trading_signal_output_accuracy' in history_dict:\n",
    "            plt.subplot(2, 3, 2)\n",
    "            plt.plot(epochs_range, history_dict['trading_signal_output_accuracy'], label='Train Accuracy')\n",
    "            plt.plot(epochs_range, history_dict['val_trading_signal_output_accuracy'], label='Validation Accuracy')\n",
    "            plt.title('Trading Signal Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.legend()\n",
    "        else:\n",
    "             print(\"Métriques 'trading_signal_output_accuracy' non trouvées dans l'historique.\")\n",
    "\n",
    "        # 3. Volatility RMSE (si disponible)\n",
    "        if 'volatility_output_rmse' in history_dict and 'val_volatility_output_rmse' in history_dict:\n",
    "            plt.subplot(2, 3, 3)\n",
    "            plt.plot(epochs_range, history_dict['volatility_output_rmse'], label='Train RMSE')\n",
    "            plt.plot(epochs_range, history_dict['val_volatility_output_rmse'], label='Validation RMSE')\n",
    "            plt.title('Volatility RMSE')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.legend()\n",
    "        else:\n",
    "             print(\"Métriques 'volatility_output_rmse' non trouvées dans l'historique.\")\n",
    "\n",
    "        # 4. Market Regime Accuracy (si disponible)\n",
    "        if 'market_regime_output_accuracy' in history_dict and 'val_market_regime_output_accuracy' in history_dict:\n",
    "            plt.subplot(2, 3, 4)\n",
    "            plt.plot(epochs_range, history_dict['market_regime_output_accuracy'], label='Train Accuracy')\n",
    "            plt.plot(epochs_range, history_dict['val_market_regime_output_accuracy'], label='Validation Accuracy')\n",
    "            plt.title('Market Regime Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.legend()\n",
    "        else:\n",
    "             print(\"Métriques 'market_regime_output_accuracy' non trouvées dans l'historique.\")\n",
    "\n",
    "        # 5. Volatility MAE (si disponible et intéressante)\n",
    "        if 'volatility_output_mae' in history_dict and 'val_volatility_output_mae' in history_dict:\n",
    "            plt.subplot(2, 3, 5)\n",
    "            plt.plot(epochs_range, history_dict['volatility_output_mae'], label='Train MAE')\n",
    "            plt.plot(epochs_range, history_dict['val_volatility_output_mae'], label='Validation MAE')\n",
    "            plt.title('Volatility MAE')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('MAE')\n",
    "            plt.legend()\n",
    "        else:\n",
    "             print(\"Métriques 'volatility_output_mae' non trouvées dans l'historique.\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Données de perte non trouvées dans l'historique, impossible de générer les graphiques.\")\n",
    "else:\n",
    "    print(\"Visualisation sautée car l'entraînement n'a pas eu lieu.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin du Notebook\n",
    "\n",
    "Le modèle a été entraîné (si les données étaient correctes), évalué, et le meilleur modèle a été sauvegardé. Les courbes d'apprentissage donnent un aperçu de la convergence et des éventuels problèmes (sur-apprentissage, etc.)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
