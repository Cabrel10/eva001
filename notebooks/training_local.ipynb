{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement du Modèle Morningstar (Version Locale)\n",
    "\n",
    "Ce notebook entraîne le modèle `enhanced_hybrid_model` localement en utilisant les données préparées pour un actif spécifique (par défaut 'sol')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de base\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path('/home/morningstar/Desktop/crypto_robot/Morningstar')\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(f\"Répertoire projet: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des dépendances (si nécessaire)\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données et préparation des labels\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model.training.data_loader import load_and_split_data\n",
    "from model.architecture.enhanced_hybrid_model import build_enhanced_hybrid_model\n",
    "\n",
    "ASSET_NAME = 'sol'\n",
    "DATA_PATH = PROJECT_ROOT / 'data' / 'processed' / f'{ASSET_NAME}_final.parquet'\n",
    "\n",
    "# Vérification des colonnes disponibles\n",
    "print(\"Colonnes disponibles dans le fichier:\")\n",
    "print(pd.read_parquet(DATA_PATH).columns.tolist())\n",
    "\n",
    "# Chargement des données brutes\n",
    "data = pd.read_parquet(DATA_PATH)\n",
    "\n",
    "# Renommage des colonnes pour correspondre aux noms de sortie du modèle\n",
    "data = data.rename(columns={\n",
    "    'trading_signal': 'signal',\n",
    "    'volatility': 'volatility_quantiles',\n",
    "    'market_regime': 'market_regime'\n",
    "})\n",
    "\n",
    "# Création de volatility_regime si nécessaire\n",
    "if 'volatility_regime' not in data.columns:\n",
    "    data['volatility_regime'] = data['market_regime']  # Utiliser market_regime comme placeholder\n",
    "\n",
    "# Conversion des régimes textuels en entiers\n",
    "regime_map = {'bearish_placeholder': 0, 'sideways_placeholder': 1, 'bullish_placeholder': 2}\n",
    "if 'market_regime' in data.columns and data['market_regime'].dtype == 'object':\n",
    "    data['market_regime'] = data['market_regime'].map(regime_map).fillna(-1).astype(int)\n",
    "if 'volatility_regime' in data.columns and data['volatility_regime'].dtype == 'object':\n",
    "    data['volatility_regime'] = data['volatility_regime'].map(regime_map).fillna(-1).astype(int)\n",
    "\n",
    "# Préparation de sl_tp à partir de level_sl et level_tp\n",
    "if 'level_sl' in data.columns and 'level_tp' in data.columns:\n",
    "    data['level_sl'] = pd.to_numeric(data['level_sl'], errors='coerce').fillna(0)\n",
    "    data['level_tp'] = pd.to_numeric(data['level_tp'], errors='coerce').fillna(0)\n",
    "else:\n",
    "    print(\"Warning: Colonnes level_sl ou level_tp manquantes\")\n",
    "\n",
    "# Sauvegarde temporaire pour charger avec data_loader\n",
    "temp_path = PROJECT_ROOT / 'data' / 'processed' / 'temp.parquet'\n",
    "data.to_parquet(temp_path)\n",
    "\n",
    "# Chargement avec la nouvelle version de data_loader\n",
    "output_names = ['signal', 'volatility_quantiles', 'volatility_regime', 'market_regime', 'sl_tp']\n",
    "X, y_dict = load_and_split_data(\n",
    "    file_path=temp_path,\n",
    "    label_columns=output_names,\n",
    "    as_tensor=True\n",
    ")\n",
    "\n",
    "# Suppression du fichier temporaire\n",
    "temp_path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation train/validation\n",
    "num_samples = X.shape[0]\n",
    "num_val = int(num_samples * 0.2)\n",
    "X_train, X_val = X[:num_samples-num_val], X[num_samples-num_val:]\n",
    "y_train = {k: v[:num_samples-num_val] for k, v in y_dict.items()}\n",
    "y_val = {k: v[num_samples-num_val:] for k, v in y_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des inputs pour modèle hybride (avec placeholder pour LLM)\n",
    "print(\"\\nPréparation des dictionnaires d'input pour le modèle hybride...\")\n",
    "llm_embedding_dim = 768 # Doit correspondre à la définition du modèle\n",
    "\n",
    "llm_placeholder_train = np.zeros((X_train.shape[0], llm_embedding_dim), dtype=np.float32)\n",
    "X_train_dict = {\n",
    "    'technical_input': X_train,\n",
    "    'llm_input': llm_placeholder_train\n",
    "}\n",
    "\n",
    "llm_placeholder_val = np.zeros((X_val.shape[0], llm_embedding_dim), dtype=np.float32)\n",
    "X_val_dict = {\n",
    "    'technical_input': X_val,\n",
    "    'llm_input': llm_placeholder_val\n",
    "}\n",
    "print(\"Dictionnaires d'inputs créés.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du modèle\n",
    "input_shape = (X_train.shape[1],)\n",
    "# Déterminer dynamiquement le nombre de classes si possible\n",
    "num_signal_classes = int(tf.reduce_max(y_train['signal'])) + 1 if 'signal' in y_train else 2\n",
    "num_market_regime_classes = int(tf.reduce_max(y_train['market_regime'])) + 1 if 'market_regime' in y_train else 3\n",
    "\n",
    "model = build_enhanced_hybrid_model(\n",
    "    input_shape=input_shape,\n",
    "    llm_embedding_dim=llm_embedding_dim,\n",
    "    num_trading_classes=num_signal_classes,\n",
    "    num_regime_classes=num_market_regime_classes\n",
    ")\n",
    "\n",
    "# Configuration de la compilation\n",
    "losses = {\n",
    "    'signal': 'sparse_categorical_crossentropy',\n",
    "    'volatility_quantiles': 'mse',\n",
    "    'volatility_regime': 'sparse_categorical_crossentropy',\n",
    "    'market_regime': 'sparse_categorical_crossentropy',\n",
    "    'sl_tp': 'mse'\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    'signal': ['accuracy'],\n",
    "    'volatility_quantiles': ['mae'],\n",
    "    'volatility_regime': ['accuracy'],\n",
    "    'market_regime': ['accuracy'],\n",
    "    'sl_tp': ['mae']\n",
    "}\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=losses,\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "MODEL_PATH = PROJECT_ROOT / 'model' / 'training' / 'morningstar_local.h5'\n",
    "\n",
    "history = model.fit(\n",
    "    x=X_train_dict,  # Utiliser le dictionnaire d'inputs\n",
    "    y=y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val_dict, y_val), # Utiliser les dictionnaires pour la validation aussi\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=MODEL_PATH,\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss'\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation et visualisation des résultats\n",
    "results = model.evaluate(X_val_dict, y_val) # Utiliser le dictionnaire pour l'évaluation\n",
    "print(\"Résultats d'évaluation:\")\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(f\"{name}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
