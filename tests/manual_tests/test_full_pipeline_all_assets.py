import os
import subprocess
import pandas as pd
from pathlib import Path

# Configuration
tokens = ["BTCUSDT", "ETHUSDT", "BNBUSDT", "SOLUSDT", "MATICUSDT"] # Utilisation de symboles standards pour Binance/Kucoin (√† v√©rifier si besoin)
exchange = "kucoin" # Chang√© pour Kucoin
timeframe = "15m"
start = "2024-01-01" # Date historique valide
end = "2024-04-01"   # Date historique valide
expected_columns = 38 # Nombre de colonnes attendu en sortie

# Dossiers
raw_dir = Path("data/raw")
processed_dir = Path("data/processed")
logs_dir = Path("logs") # Bien que non utilis√© directement ici, c'est bien de le d√©finir

raw_dir.mkdir(exist_ok=True)
processed_dir.mkdir(exist_ok=True)
logs_dir.mkdir(exist_ok=True)

success_count = 0
total_tokens = len(tokens)

print(f"--- D√©marrage du Test Complet du Pipeline pour {total_tokens} Tokens ---")
print(f"Configuration: Exchange={exchange}, Timeframe={timeframe}, P√©riode={start} √† {end}")
print(f"Colonnes attendues en sortie: {expected_columns}")

for token in tokens:
    # Ajuster le nom du fichier pour utiliser le symbole de base (sans suffixes comme _SPBL)
    symbol_base = token.replace("USDT", "").replace("_SPBL", "").lower()
    raw_path = raw_dir / f"{symbol_base}_raw.csv"
    output_path = processed_dir / f"{symbol_base}_final.parquet"

    print(f"\n=== Traitement de {token} ===") # Afficher le token original pour info

    # --- √âtape 1 : T√©l√©chargement des donn√©es brutes ---
    print(f"[1/3] T√©l√©chargement des donn√©es brutes vers {raw_path}...")
    cmd_download = [
        "python", "utils/api_manager.py",
        "--token", token,
        "--exchange", exchange,
        "--start", start,
        "--end", end,
        "--timeframe", timeframe,
        "--output", str(raw_path) # Convertir Path en string pour subprocess
    ]
    result_download = subprocess.run(cmd_download, capture_output=True, text=True, check=False) # check=False pour g√©rer l'erreur manuellement

    # V√©rification du t√©l√©chargement
    if result_download.returncode != 0 or not raw_path.exists() or raw_path.stat().st_size < 1000: # Seuil de taille bas pour √™tre s√ªr qu'il y a des donn√©es
        print(f"‚ùå √âchec t√©l√©chargement {token}.")
        if result_download.stderr:
            print(f"   Erreur: {result_download.stderr.strip()}")
        elif not raw_path.exists():
            print(f"   Erreur: Fichier {raw_path} non cr√©√©.")
        elif raw_path.stat().st_size < 1000:
             print(f"   Erreur: Fichier {raw_path} semble trop petit ({raw_path.stat().st_size} bytes).")
        continue
    else:
        print(f"‚úÖ Donn√©es brutes t√©l√©charg√©es ({raw_path.stat().st_size} bytes).")


    # --- √âtape 2 : Transformation via pipeline ---
    print(f"[2/3] Lancement du pipeline de transformation vers {output_path}...")
    cmd_pipeline = [
        "python", "data/pipelines/data_pipeline.py",
        "--input", str(raw_path),    # Argument corrig√©
        "--output", str(output_path) # Argument corrig√©
    ]
    result_pipeline = subprocess.run(cmd_pipeline, capture_output=True, text=True, check=False)

    # V√©rification de la sortie du pipeline
    if result_pipeline.returncode != 0 or not output_path.exists():
        print(f"‚ùå √âchec pipeline {token}.")
        if result_pipeline.stderr:
            print(f"   Erreur: {result_pipeline.stderr.strip()}")
        elif not output_path.exists():
             print(f"   Erreur: Fichier {output_path} non cr√©√©.")
        continue
    else:
        print(f"‚úÖ Pipeline termin√©.")


    # --- √âtape 3 : Validation du fichier Parquet ---
    print(f"[3/3] Validation du fichier {output_path}...")
    try:
        df = pd.read_parquet(output_path)
        shape = df.shape
        columns_count = len(df.columns)
        print(f"   üìä Shape: {shape}")
        print(f"   üìé Colonnes trouv√©es: {columns_count}")

        if columns_count == expected_columns:
            print(f"   üéØ Structure valid√©e ({expected_columns} colonnes) ‚úÖ")
            success_count += 1
        else:
            print(f"   ‚ö†Ô∏è Mauvais nombre de colonnes (attendu: {expected_columns}, trouv√©: {columns_count}).")
            # print(f"      Colonnes: {df.columns.tolist()}") # D√©commenter pour voir les colonnes

    except Exception as e:
        print(f"‚ùå Erreur lors de la lecture ou validation du fichier {output_path}: {e}")
        continue

# --- R√©sum√© Final ---
print(f"\n--- Test Complet du Pipeline Termin√© ---")
if success_count == total_tokens:
    print(f"‚úÖüî• Tous les {total_tokens}/{total_tokens} jeux de donn√©es ont √©t√© trait√©s et valid√©s avec succ√®s !")
else:
    print(f"‚ö†Ô∏è {success_count}/{total_tokens} jeux de donn√©es valid√©s avec succ√®s.")

print("-----------------------------------------")
